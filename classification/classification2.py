# -*- coding: utf-8 -*-
"""classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/192yExR1LHF9R1znd8O1YtOM0qrv83Y1d
"""

# This program provides 3 different classification methods for the detection of cancer cell in the FCS file


# Import libraries
import numpy as np
import pandas as pd
import os
from pylab import *
import seaborn as sns

import FlowCytometryTools
from FlowCytometryTools import FCMeasurement
from FlowCytometryTools import ThresholdGate
from FlowCytometryTools import FCPlate
from FlowCytometryTools.core.graph import plot_heat_map

from google.colab import files

datafile = 'a06_ut_sys.fcs'

tsample = FCMeasurement(ID='Test Sample', datafile=datafile)
type(tsample)
df = (tsample.data)
df.tail(60)

df.isin([0]).sum()

df['diagnosis'] = df.apply(lambda row: 1 if row['FSC-A']==0 or row['FSC-H']==0 or row['SSC-A']==0 or row['SSC-H']==0 else 0, axis=1)
# df

df.isna().sum()

df.shape
df.columns

# Count the number of Malignant(1) and Benign(0) cells
df['diagnosis'].value_counts()

# Visualize the number of M and B cells
sns.countplot(df['diagnosis'], label='count')

df = df [['diagnosis', 'FSC-A','FSC-H', 'SSC-A', 'SSC-H']]
 df

df.dtypes

sns.pairplot(df.iloc[:, 0:5], hue='diagnosis')

# Find correlation among columns
plt.figure(figsize=(20,10))
sns.heatmap(df.iloc[:, 0:5].corr(), annot=True, fmt='.0%')

# Split the data into dependent(Y) and independent sets(X)
X = df.iloc[:, 1:5].values
Y = df.iloc[:, 0].values

type(X)

# Split the dataset into 70% training and 30% testing data sets
from sklearn.model_selection import train_test_split

X_train,X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=0)
X_train

# Scale the data - featture scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)
X_test

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# Create a function for all models
def models(X_train, Y_train):
  # Logistic Regression
  log = LogisticRegression(random_state=0)
  log.fit(X_train, Y_train)
  print(log.score(X_train, Y_train))

  # Decision Tree
  tree = DecisionTreeClassifier(criterion='entropy', random_state=0)
  tree.fit(X_train, Y_train)

  # Random Forest RF
  forest = RandomForestClassifier(n_estimators = 10, criterion='entropy', random_state=0)
  forest.fit(X_train, Y_train)

  return log, tree, forest

model = models(X_train, Y_train)

# Show accuracy using the trained models
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

model_names = ['Logistic Regression', 'Decision Tree', 'Random Forest']

print('######### TRAIN Accuracy ##########')
print()
for i in range(len(model)):
  print('===> ' + model_names[i])
  print(classification_report(Y_train, model[i].predict(X_train) ))
  print(accuracy_score(Y_train, model[i].predict(X_train)))
  print()

print('######### TEST Accuracy ##########')
print()
for i in range(len(model)):
  print('===> ' + model_names[i])
  print(classification_report(Y_test, model[i].predict(X_test) ))
  print(accuracy_score(Y_test, model[i].predict(X_test)))
  print()

print('######### PREDICT Cancer ##########')
print()

uploaded = files.upload()

datafile = 'IP_0.0_Minutes_120.fcs'
tsample = FCMeasurement(ID='Test Sample', datafile=datafile)
type(tsample)
df2 = (tsample.data)
df2

df2 = df2 [['FSC-A','SSC-A', 'SSC-A', 'FSC-A']]

df2.tail(10)
X2 = df2.iloc[:, 0:5].values
X2 = sc.fit_transform(X2)
X2

print()
for i in range(len(model)):
  print('===> ' + model_names[i])
  a =  model[i].predict(X2)

  unique_elements, counts_elements = np.unique(a, return_counts=True)
  print(np.asarray((unique_elements, counts_elements)))